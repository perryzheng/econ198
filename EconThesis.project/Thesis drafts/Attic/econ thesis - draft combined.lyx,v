head	1.7;
access;
symbols;
locks; strict;
comment	@# @;
expand	@b@;


1.7
date	2010.03.19.19.28.30;	author idw3;	state dead;
branches;
next	1.6;

1.6
date	2010.03.19.01.48.55;	author xz27;	state Exp;
branches;
next	1.5;

1.5
date	2010.03.03.19.46.33;	author idw3;	state Exp;
branches;
next	1.4;

1.4
date	2010.03.03.18.37.02;	author xz27;	state Exp;
branches;
next	1.3;

1.3
date	2010.03.03.18.31.02;	author idw3;	state Exp;
branches;
next	1.2;

1.2
date	2010.03.03.18.26.08;	author xz27;	state Exp;
branches;
next	1.1;

1.1
date	2010.02.24.20.15.30;	author idw3;	state Exp;
branches;
next	;


desc
@@


1.7
log
@*** empty log message ***
@
text
@#LyX 1.6.5 created this file. For more info see http://www.lyx.org/
\lyxformat 345
\begin_document
\begin_header
\textclass article
\begin_preamble
\usepackage{amsmath}
\end_preamble
\use_default_options true
\language english
\inputencoding auto
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\cite_engine basic
\use_bibtopic false
\paperorientation portrait
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\defskip medskip
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\author "" 
\author "" 
\end_header

\begin_body

\begin_layout Title
\paragraph_spacing double
[Econ Thesis Title]
\end_layout

\begin_layout Author
\paragraph_spacing double
Irvin Di Wang and Perry Zheng
\end_layout

\begin_layout Author
\paragraph_spacing double
Professor Emma Rasiel and Professor Aino Levonmaa, Faculty Advisors
\end_layout

\begin_layout Standard
\paragraph_spacing double
Honors Thesis submitted in partial fulfillment of the requirements for Graduatio
n with Distinction in Economics in Trinity College of Duke University.
\end_layout

\begin_layout Date
\paragraph_spacing double
Duke University
\end_layout

\begin_layout Date
\paragraph_spacing double
Durham, North Carolina
\end_layout

\begin_layout Date
\paragraph_spacing double
April 15, 2010
\end_layout

\begin_layout Standard
\paragraph_spacing double
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Section*
\paragraph_spacing double
Table of Contents
\end_layout

\begin_layout Standard
\paragraph_spacing double
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Section*
\paragraph_spacing double
Acknowledgements
\end_layout

\begin_layout Standard
\paragraph_spacing double
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Abstract
\paragraph_spacing double
[Abstract text]
\end_layout

\begin_layout Standard
\paragraph_spacing double
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Section
\paragraph_spacing double
Introduction
\end_layout

\begin_layout Standard
\paragraph_spacing double
[Introduction text]
\end_layout

\begin_layout Section
\paragraph_spacing double
Literature Review
\end_layout

\begin_layout Subsection
\paragraph_spacing double
JPMorgan's paper - ignore
\end_layout

\begin_layout Standard
\paragraph_spacing double
JPMorgan’s (2009) “Non-Normality of Market Returns” paper provides a real
 world application and verification of the use of fat tail distributions
 and CVaR as a risk measure in an asset allocation framework.
  They conclude that a fat tail distribution better describes the real world
 market environment than a normal distribution.
  The paper also briefly touches on CVaR as a risk measure that better accounts
 for downside risk than variance.
  JPMorgan first tests for 1st degree auto-correlation between consecutive
 months using the Ljung-Box test, and then ‘unsmooths’ the data to take
 out significant autocorrelation.
  Then, the technique used is to fit the historical data to a normal distributio
n and a fat tail (Generalized Pareto) distribution, followed by the use
 of copulas to account for the joint distribution of asset classes.
  In other words, the copulas account for the probability of the behavior
 of all asset classes together.
  The historical data is then fit to a normal copula (Gaussian copula) and
 a Student’s t-copula (fat tail joint distribution), which accounts for
 a higher probability of all asset classes going down together than a normal
 copula.
  The paper then draws simulations out of these two copulas to simulate
 a set of returns for a time period and compares it to the historical data.
 It is shown that the Student’s t-copula more closely fits the historical
 data, especially the extreme events, than does the normal copula.
 The paper then briefly looks at asset allocation using CVaR as a risk measure.
  It shows that the use of a Student’s t-copula assumption provides a lower
 CVaR (lower downside risk) than does the use of a normal copula.
  JPMorgan’s paper demonstrates an implementation of the t-copula and CVaR
 in an asset allocation framework fits historical data better than does
 the traditional mean-variance framework.
  Our research will focus on the implementation and continuation of this
 asset allocation model with constraints, cash reserves, rebalancing, and
 the VIX as an asset class.
  We will also look at the historical accuracy and advantage of using our
 asset allocation model in comparison to the traditional mean-variance asset
 allocation framework.
  
\end_layout

\begin_layout Subsection
\paragraph_spacing double
Rebalancing 
\end_layout

\begin_layout Standard
\paragraph_spacing double
The literature reviewed up to this point only considers a single time frame
 portfolio optimization, where an asset allocation is set at the beginning
 of the period and the portfolio is untouched until the end of the investment
 period.
  Master (2003) offers a simple rebalancing strategy, which involves setting
 a target allocation.
  The invesntor only rebalances when the allocation deviates beyond a set
 of trigger points.
  For instance, if the trigger point is 3% for all asset classes, then an
 investor only rebalances when the weight for any asset class deviates more
 than 3% from the target weight.
  This is also known as a tolerance band rebalancing strategy.
  According to Master, any rebalancing strategy should incorporate some
 basic assumptions.
  The benefit of rebalancing is inversely proportional to an investor's
 risk preference: if an investor is risk tolerant, meaning he is willing
 to endure higher risk for higher potential returns, then his benchmarks
 for rebalancing will be smaller, meaning he will rebalnace less often.
  It is also worthwhile noting that the benefit of rebalancing rises geometrical
ly.
  For example, rebalancing at deviation of 6% of target target allocation
 provides up to four times as much benefit as rebalancing at deviation of
 3% of target allocation.
  Mathematically this can be represented as 
\begin_inset Formula $\text{Rebalancing Benefit }=\frac{{\text{Tracking Error}\cdot\delta}}{2\cdot\text{Risk Tolerance}}$
\end_inset

 where 
\begin_inset Formula $\delta$
\end_inset

 is the deviation where delta is the deviation from the target allocation
 and Tracking Error represents how closely a portfolio follows the target
 allocation to which it is benchmarked.
  On the other hand, rebalancing also involves transactions of asset classes,
 which incurs costs.
  While the benefit of rebalancing rises geometrically, transaction costs
 of rebalancing are linear: selling twice as much of an asset would cost
 twice as much.
  The net benefit of rebalancing is the difference between the benefit of
 rebalancing and the cost of rebalancing.
  
\end_layout

\begin_layout Standard
\paragraph_spacing double
Sun (2006) extends the idea of Master’s paper to incorporate dynamic programming
 to minimize the cost of rebalancing.
  Walter applies the idea to CAPM models, which assume that asset returns
 are stationary, and that mean and variance are the primary portfolio statistics
 of interest.
  The optimal strategy is to rebalance only when the expected cost of trading
 is less than the expected cost of doing nothing.
  His conclusion is that periodic or tolerance band rebalancing provide
 suboptimal rebalance portfolios.
  However, by treating the rebalancing problem as an optimization problem
 and solving it using dynamic programming, Sun was able to reduce overall
 costs of portfolio rebalancing.
  
\end_layout

\begin_layout Standard
\paragraph_spacing double
Taking rebalancing one step further, Guastaroba (2009) applies rebalancing
 strategies to a portfolio optimization model that uses Conditional Value
 at Risk (CVaR) as the risk measure.
  The model incorporates rebalancing as a set of linear programming constraints.
  He introduces a decision variable that indicates whether to rebalance
 based on whether the portfolio allocation deviated from a certain quantile.
  He also assume fixed and variable transacton costs.
  During every rebalancing period, an investor rebalances if net portfolio
 return, taking into account fixed and proportional transaction costs, is
 at least the predetermined required return.
  The paper then uses four in-sample-out-of-sample windows to test the model
 for different levels of minimum required returns (0, 5%, and 10%) and different
 quantile measures (1%, 5%, 10% and 25%).
  Based on the back-tracking results, he concludes that for a very risk-averse
 investor the best choice is to rebalance two or three times in six months.
  On the other hand, a less risk-averse investor should rebalance one time
 or not rebalance at all.
  
\end_layout

\begin_layout Standard
\paragraph_spacing double
These papers give us a starting point for incorporating rebalancing into
 our model.
  Our goal is to analyze and compare the different rebalancing strategies:
 a simple periodic strategy in which we rebalance every few months, a tolerance-
band strategy in which we rebalance when allocation deviates beyond a predetermi
ned range, or a dynamic programming approach that actively calculates the
 expected cost of future transactions.
  We will then incorporate the use of t-copulas for fat tails, CVaR as a
 risk measure, and rebalancing as a portfolio strategy to produce a realistic
 asset allocation framework for a large institutional investor such as an
 endowment.
  
\end_layout

\begin_layout Section
\paragraph_spacing double
Concepts & Methods
\end_layout

\begin_layout Standard
\paragraph_spacing double
[Methods]
\end_layout

\begin_layout Standard
\paragraph_spacing double
[Describe CVaR, t-Copulas, rebalancing here]
\end_layout

\begin_layout Standard
\paragraph_spacing double
[Use formulas]
\end_layout

\begin_layout Standard
\paragraph_spacing double
[Show the application process of the theory, how are simulations used? Simulatio
ns as estimate of analytical/theoretical formulas]
\end_layout

\begin_layout Subsection
\paragraph_spacing double
Methods Overview - ignore
\end_layout

\begin_layout Standard
\paragraph_spacing double
We have reproduced and implemented the concepts of the JPMorgan paper as
 a starting point for our investigation of the value of rebalancing as a
 consideration for allocating assets in the mean-CVaR framework.
  The historical return data of our asset classes benchmarks are first tested
 for first order monthly autocorrelation and then 'unsmoothed' to remove
 autocorrelation.
  Next, the historical return data are individually fit to marginal Generalized
 Pareto Distributions before combining the historical correlation matrix
 and fit to a joint t-Copula distribution.
  We then run simulations for monthly returns for 3 years by drawing out
 of the joint t-Copula distribution.
  We optimize our efficient frontier for return and CVaR based on this simulatio
n dataset only.
  
\end_layout

\begin_layout Standard
\paragraph_spacing double
We begin the one-period (buy and hold) CVaR analysis by establishing a baseline
 for comparison.
  The weights of the mean-variance efficient frontiers for historical arithmetic
 averages and unsmoothed historical arithmetic averages are applied to our
 simulation data to determine the CVaR and return of each weight.
  The pseudo-mean-CVaR efficient frontier derived from these mean-variance
 weights are used as the starting weights for finding the optimal portfolio,
 assuming there is another weight that can provide a lower CVaR and/or a
 higher return.
  We use MATLAB's built-in optimization function 'fmincon' for finding an
 optimal efficient frontier.
  The objective function to be minimized is the CVaR while the non-linear
 constraint to be satisfied is a set return, the average return of the portfolio
 across the simulations must be approximately equal to the constraint.
  We generate an efficient frontier by using each of the historical mean-varianc
e portfolio returns as our non-linear constraints for finding the minimum
 CVaR.
  
\end_layout

\begin_layout Standard
\paragraph_spacing double
Next, we investigate the ability for multi-period optimization and account
 for rebalancing in constructing the efficient frontier.
  We first implement a simple model that rebalances back to the target weight
 every 12 months and incurs no transaction costs.
  We integrate the rebalancing function to our objective function in calculating
 portfolio CVaRs and into our non-linear constraint for calculating average
 portfolio returns across all simulations for our 'fmincon' optimization.
  We are currently investigating the use of a decision function for determining
 whether to rebalance at each specified time period based on transaction
 cost, deviation from the target weights, change in portfolio variance,
 or change in portfolio CVaR.
  
\end_layout

\begin_layout Standard
\paragraph_spacing double
We will compare our CVaR based efficient frontiers to their respective mean-vari
ance counterparts to determine the strengths and weaknesses of both methods.
  We will use historical data as well as newly generated simulation data
 for testing hypotheses.
\end_layout

\begin_layout Subsection
\paragraph_spacing double
t-Copula
\end_layout

\begin_layout Standard
\paragraph_spacing double
In traditional mean-variance portfolio optimization frameworks, Monte Carlo
 simulations are run from a Gaussian (normal) joint distribution for the
 basket of asset classes.
 The shortfall of this method is the thinness of the tail, implying a very
 low likelihood for situations where all asset classes are falling significantly
 in market crash scenarios.
 The advantage of using a t-copula is it can accomodate higher probabilities
 of joint events (crashes or bubbles).
 A copula combines marginal cumulative distribution functions (CDF) and
 historical data of each asset class to create a best fit multivariate joint
 distribution.
 A Gaussian copula assumes a multivariate normal distribution whereas a
 t-copula utilizes a multivariate Student’s t-distribution, allowing for
 fatter tails.
 The t-copula provides a more accurate representation of real world financial
 markets and the probability of extreme events (Demarta and McNeil, 2004).
\end_layout

\begin_layout Subsubsection
\paragraph_spacing double
Implementation
\end_layout

\begin_layout Standard
\paragraph_spacing double
The historical data of each individual asset class are first fit to independent,
 marginal Generalized Pareto Distribution; this GPD fit is piecewise so
 that a different function is fit to the lower tail and upper tail to account
 for marignal distribution fat tails.
 Next, independent marginal CDFs are transformed into their inverses, creating
 a uniform distribution over [0, 1].
 The historical returns are then applied to their respective inverse CDF's
 to determine a marginal probability of occurence.
 Using MATLAB's 
\family sans
copulafit()
\family default
 function, a multivariate t-distribution fit is then constructed over these
 inverse CDF historical probabilities to produce a t-copula that is identified
 by a new correlation matrix and a single degree of freedom.
 The resulting t-Copula fit is centered at zero with characteristic fat
 tails, similar to a standard normal distribution, and is used for generating
 simulations.
 
\end_layout

\begin_layout Standard
\paragraph_spacing double
In order to simulate a certain number of months into the future, we generate
 multiple single month returns for all asset classes.
 A single month's return is simulated for all asset classes by generating
 multivariate random numbers from the t-Copula fit using MATLAB's 
\family sans
mvtrnd
\family default
() function and applying it to the following formula:
\end_layout

\begin_layout Standard
\paragraph_spacing double
\begin_inset Formula \begin{equation}
\text{Simulated One Month Return}=\mu+\sigma\cdot\vec{x}\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing double
Where 
\begin_inset ERT
status open

\begin_layout Plain Layout

$
\backslash
mu$
\end_layout

\end_inset

 is a vector of the average historical, empirical monthly returns for each
 asset class, 
\begin_inset ERT
status open

\begin_layout Plain Layout

$
\backslash
sigma$
\end_layout

\end_inset

 is a vector of the historical, empirical standard deviations for each asset
 class, and 
\begin_inset ERT
status open

\begin_layout Plain Layout

$
\backslash
vec{x}$
\end_layout

\end_inset

 is a vector of the generated multivariate t random numbers.
 We use the average historical, empirical monthly returns and historical,
 empirical standard deviations of each asset class in our research for consisten
cy and objectiveness; it is possible to use expected returns and standard
 deviations for applications or further research.
 When simulations are drawn out of a t-copula, the likelihood of a market
 crash scenario is an order of magnitude higher than that of a Gaussian
 copula.
 
\end_layout

\begin_layout Subsection
\paragraph_spacing double
Conditional Value at Risk (CVaR) as Risk Measure
\end_layout

\begin_layout Standard
\paragraph_spacing double
Variance provides a mathematically simple measure of risk for asset allocation,
 but it adds little value as a relevant measure of downside risk.
 Variance accounts for both upside risk and downside risk since it is simply
 a measure of the sample’s average squared deviation from the arithmetic
 mean.
 When investment managers look at risk, they are typically concerned with
 downside risk or losses and view upside risk (which may be referred to
 as “excess return”) as a result of skill, expertise, good fortune, and
 value added.
 Value-at-risk (VaR) has been incorporated as another risk measure that
 aims to better account for downside risk than variance.
 VaR is the minimum loss expected at a certain confidence level (typically
 5%) and can be calculated by taking the value of the return that specifies
 the border of the specified (5%) mark on a probability density function
 (PDF) of return data (either historical or simulated).
 Although VaR does a better job of accounting for downside risk than variance,
 it does not capture the extent of the possible losses beyond the specified
 (5%) cutoff.
 It is possible to have two PDF’s with the same VaR (loss associated with
 the cutoff of 5%) but one with a fatter tail and greater losses to the
 left of the specified (5%) cutoff.
 Conditional value-at-risk (CVaR) attempts to rectify this problem: it is
 the expected loss given a loss beyond the value-at-risk, and can be calculated
 as a weighted average of the worst case losses.
 Furthermore, CVaR is a better risk measure than VaR because it is a “coherent
 risk measure” and is “sub-additive and convex” (p.
 3, Krohmal, Palmquist, and Uryasev, 2002).
 The CVaR of a portfolio is always less than or equal to the sum of the
 CVaR of the weights of the individual asset classes and can be extended
 from continuous probability distributions to discrete screnarios such as
 in simulations, allowing for proper optimization using simulations or discrete
 distributions and eliminating anomolous results such as multiple local
 minima.
 
\end_layout

\begin_layout Standard
\paragraph_spacing double
Rockafellar and Uryasev (1999) demonstrate the use of CVaR in an asset allocatio
n framework and the ability to optimize CVaR using linear programming methods.
 The ability to use linear programming stems from the way CVaR is calculated.
 Theoretically, CVaR is simply the average value beyond the specified cutoff
 (5%) calculated using the calculus of integrals.
 Rockafellar and Uryasev demonstrated that the use of simulations and a
 summation to estimate the theoretical CVaR can be exploited to find the
 minimum CVaR.
 The minimization of CVaR in most situations also provides a minimum VaR
 because CVaR is always greater than VaR.
 Only in situations of extreme skewness does the minimum VaR differ greatly
 from the minimum CVaR.
 Rockafellar and Uryasev demonstrate the theoretical and mathematical possibilit
y of optimizing CVaR for portfolio asset allocation.
 
\end_layout

\begin_layout Subsubsection
\paragraph_spacing double
Implementation
\end_layout

\begin_layout Standard
\paragraph_spacing double
In order to calculate the CVaR of a certain portfolio over a set of simulations,
 we wrote a MATLAB script that sorts the average returns of all the simulations
 from lowest to highest and takes the average of the lowest 
\begin_inset ERT
status open

\begin_layout Plain Layout

$
\backslash
beta * Number of Simulation$
\end_layout

\end_inset

 values, where 
\begin_inset ERT
status open

\begin_layout Plain Layout

$
\backslash
beta$
\end_layout

\end_inset

 is the desired CVaR level, such as 5%.
 
\end_layout

\begin_layout Standard
\paragraph_spacing double
\begin_inset Formula \begin{equation}
\beta\text{-CVaR}=\frac{{1}}{(\beta\cdot n)}\sum_{i=1}^{\beta\cdot n}r_{i}\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing double
Where 
\begin_inset ERT
status open

\begin_layout Plain Layout

$n$
\end_layout

\end_inset

 is the number of simulations, 
\begin_inset ERT
status open

\begin_layout Plain Layout

$
\backslash
vec{r}$
\end_layout

\end_inset

 is a vector of average returns of each simulation sorted from lowest to
 highest return, and 
\begin_inset ERT
status open

\begin_layout Plain Layout

$
\backslash
beta$
\end_layout

\end_inset

 is the desired CVaR level.
 
\end_layout

\begin_layout Subsection
\paragraph_spacing double
Analytical Mean-Variance Optimization
\end_layout

\begin_layout Standard
\paragraph_spacing double
Markowitz (1952) pioneered the use of the normal mean-variance optimization
 framework for maximizing portfolio returns and minizing portfolio risk
 (standard deviation).
 This framework analytically calculates the optimal set of portfolio returns
 and variances using the historical average return and historical standard
 deviation of each asset class along with the historical covariance between
 each pair of asset classes.
 The optimization problem can be expressed as follows:
\end_layout

\begin_layout Standard
\paragraph_spacing double
\begin_inset Formula \begin{equation}
\min_{w_{1},w_{2},...w_{n}}\text{{\sigma^{2}}}(w_{1},w_{2},...,w_{n})\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing double
\begin_inset Formula \begin{equation}
\sigma^{2}(w_{1},w_{2},...,w_{n})=\sum_{i=1}^{n}w_{i}\cdot\sigma_{i}+2\sum_{i=1}^{n}\sum_{j>i}^{n}w_{i}\cdot w_{j}\cdot\rho_{ij}\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing double
\begin_inset Formula \begin{equation}
w_{1},w_{2},...,w_{n}>0\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing double
\begin_inset Formula \begin{equation}
w_{1}+w_{2}+...+w_{n}=1\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing double
\begin_inset Formula \begin{equation}
\sum_{i=1}^{n}w_{i}\cdot r_{i}=R\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing double
where 
\begin_inset Formula $R$
\end_inset

 is the fixed portfolio monthly return rate and 
\begin_inset ERT
status open

\begin_layout Plain Layout

$r_i$
\end_layout

\end_inset

 is the average historical monthly return of each asset class.
 The optimization will use multiple levels of 
\begin_inset Formula $R$
\end_inset

 between the lowest and highest single asset class return (where the portfolio
 is 100% weighted in that single asset class) to determine the set of portfolios
 along the efficient frontier.
 
\end_layout

\begin_layout Subsubsection
\paragraph_spacing double
Implementation
\end_layout

\begin_layout Standard
\paragraph_spacing double
We use the built in MATLAB 
\family sans
portopt()
\family default
 function to calculate the normal-mean variance efficient frontier by inputing
 the average historical monthly return of each asset class, the historical
 covariance matrix, and the desired number of representative portfolios
 along the efficient frontier.
 The 
\family sans
portopt()
\family default
 function returns a set of weights for each portfolio along with its respective
 portfolio return and standard deviation.
 
\end_layout

\begin_layout Subsection
\paragraph_spacing double
Simulated Mean-CVaR Optimization Using MATLAB's 
\family sans
fmincon
\family default
 
\end_layout

\begin_layout Standard
\paragraph_spacing double
MATLAB has a built-in function called fmincon which finds the minimum of
 a constrained function.
 It takes an objective function 
\begin_inset Formula $f$
\end_inset

, a set of linear constraints, a set of nonlinear constraints as inputs,
 and tries to find the set of values which minimize 
\begin_inset Formula $f$
\end_inset

.
\end_layout

\begin_layout Subsection
\paragraph_spacing double
Simulated Mean-CVaR Optimization with Compounding
\end_layout

\begin_layout Subsubsection
\paragraph_spacing double
Implementation
\end_layout

\begin_layout Standard
\paragraph_spacing double
In our implementation, we have 5000 simulations of returns for seven asset
 classes, a set of starting weights and a set of fixed portfolio returns
 of which we derive from the Mean-Variance framework.
 Our goal is to find the set of weights that will minimize CVaR given a
 target level of return.
 
\end_layout

\begin_layout Standard
\paragraph_spacing double
When designing our simulation we have two implementation choices as to how
 to calculate the returns.
 In the compounding approach, returns from a period are compounded with
 the returns in the next period.
 In the arithmetic approach, returns from a period are added to returns
 in the next period.
 Let 
\begin_inset Formula $r_{t}$
\end_inset

 be the return during period 
\begin_inset Formula $t$
\end_inset

 and 
\begin_inset Formula $V_{t}$
\end_inset

 be the portfolio value at the end of period 
\begin_inset Formula $t$
\end_inset

, we can express the two approaches as:
\end_layout

\begin_layout Standard
\paragraph_spacing double
\begin_inset Formula \begin{equation}
\text{Compounding: }V_{t+1}=V_{t}\cdot(1+r_{t+1})\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing double
\begin_inset Formula \begin{equation}
\text{Arithemetic: }V_{t+1}=V_{t}+r_{r+1}.\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing double
We adopt the compounding approach.
 We are now ready to reconstruct our Mean-CVaR optimization with compounding
 as a nonlinear programming minimization problem which MATLAB's 
\family sans
fmincon
\family default
 can solve.
 Let 
\begin_inset Formula $w_{i}$
\end_inset

denote the weight for asset class 
\begin_inset Formula $i$
\end_inset

, 
\begin_inset Formula $R$
\end_inset

 be the fixed portfolio monthly return rate and 
\begin_inset Formula $\tilde{R}$
\end_inset

 be the calculated portfolio monthly return rate at each run of the simulation.
 We have: 
\end_layout

\begin_layout Standard
\paragraph_spacing double
\begin_inset Formula \begin{equation}
\min_{w_{1},w_{2},...w_{n}}\text{{CVaR}}(w_{1},w_{2},...,w_{n})\end{equation}

\end_inset


\begin_inset Formula \begin{equation}
w_{1},w_{2},...,w_{n}>0\end{equation}

\end_inset


\begin_inset Formula \begin{equation}
w_{1}+w_{2}+...+w_{n}=1\end{equation}

\end_inset


\begin_inset Formula \begin{equation}
\tilde{R}(w_{1},w_{2},...,w_{n})=R(w_{1},w_{2},...,w_{n})\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing double
\begin_inset Formula \begin{equation}
V_{t+1}=V_{t}\cdot(1+r_{t+1})\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing double
Our two linear constraints indicate that the weights must sum to one and
 be nonnegative (since no borrowing is allowed).
 We also have a nonlinear constraint.
 Since we want to fix return, our nonlinear constraint is that our final
 portfolio return 
\begin_inset Formula $\tilde{R}$
\end_inset

 must be the same as the given fixed portfolio return 
\begin_inset Formula $R$
\end_inset

.
\end_layout

\begin_layout Standard
\paragraph_spacing double
Our objective function is to find the weights that will minimize CVaR.
 CVaR is calculated analytically by trying out a set of asset weights for
 all 5000 simulations.
 Each simulation gives a final portfolio value, from which we can derive
 the monthly return rate by the formula: 
\end_layout

\begin_layout Standard
\paragraph_spacing double
\begin_inset Formula \begin{equation}
r=\frac{{V_{f}^{1/m}-1}}{b}\end{equation}

\end_inset

where 
\begin_inset Formula $r$
\end_inset

 is the monthly return rate, 
\begin_inset Formula $V_{f}$
\end_inset

 is the final portfolio value, 
\begin_inset Formula $m$
\end_inset

 is the number of months we simulate into the future, and 
\begin_inset Formula $b$
\end_inset

 is number of months in between which we rebalance.
 For instance, suppose we start with 1 (billion) endowment and the final
 portfolio value is 24.62 (billion).
 Suppose we simulate 36 months into the future, rebalancing every 12 months,
 Then our monthly return rate is 
\begin_inset Formula $\frac{24.62^{1/36}-1}{12}=0.0078$
\end_inset

 monthly return rate by the formula.
 For each set of weights, we carry out 5000 simulations, giving us 5000
 monthly return rates.
 We take the average of the lowest 5%, or 250 final returns, to give us
 one CVaR.
 Our objective is to find the minimum CVaR.
 We will keep trying weights in an analytical fashion until we find the
 minimun CVaR.
 The MATLAB function fmincon allows us to do this.
 The objective function and the constraints for 
\family sans
fmincon
\family default
 are precisely the same as in the nonlinear programming problem.
 
\end_layout

\begin_layout Subsection
\paragraph_spacing double
Simulated Mean-CVaR Optimization with Rebalancing and Compounding
\end_layout

\begin_layout Subsubsection
\paragraph_spacing double
Implementation
\end_layout

\begin_layout Standard
\paragraph_spacing double
The implementation is the same as in Section 3.6.1 with one additional feature.
 Every 12 months, we have to rebalance.
 We sum up the returns in that year and we distribute the portfolio value
 according to a predetermined set of weights, and then compound it with
 future returns.
 Keeping all the variables the same, and let 
\begin_inset Formula $\vec{{V}_{t}^{'}}$
\end_inset

 be the portfolio vector after rebalancing.
 
\begin_inset Formula $\vec{{V}_{t}^{'}}$
\end_inset

 contains the value of each asset class at the end of time 
\begin_inset Formula $t$
\end_inset

.
 We have the following nonlinear programming optimization problem:
\end_layout

\begin_layout Standard
\paragraph_spacing double
\begin_inset Formula \begin{equation}
\min_{w_{1},w_{2},...w_{n}}\text{{CVaR}}(w_{1},w_{2},...,w_{n})\end{equation}

\end_inset


\begin_inset Formula \begin{equation}
w_{1},w_{2},...,w_{n}>0\end{equation}

\end_inset


\begin_inset Formula \begin{equation}
w_{1}+w_{2}+...+w_{n}=1\end{equation}

\end_inset


\begin_inset Formula \begin{equation}
\tilde{R}(w_{1},w_{2},...,w_{n})=R(w_{1},w_{2},...,w_{n})\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing double
\begin_inset Formula \begin{equation}
V_{t+1}=V_{t}\cdot(1+r_{t+1})\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing double
\begin_inset Formula \begin{equation}
\vec{{V}_{t}^{'}}=V_{t}\cdot(w_{1},w_{2},..,w_{n})\end{equation}

\end_inset

where the only addition is the last rebalancing constraint.
 It specifies that at each time period 
\begin_inset Formula $t$
\end_inset

, we redistribute the value of the portfolio according to a predetermined
 set of weights which is expressed in vector form, to obtain a portfolio
 vector containing the values of each asset class.
\end_layout

\begin_layout Section
\paragraph_spacing double
Back Testing
\end_layout

\begin_layout Subsection
\paragraph_spacing double
Comparison Efficient Frontiers
\end_layout

\begin_layout Subsubsection
\paragraph_spacing double
Given Weights: Mean-CVaR Efficient Frontier
\end_layout

\begin_layout Subsubsection
\paragraph_spacing double
Given Weights: Mean-CVaR with Compounding
\end_layout

\begin_layout Subsubsection
\paragraph_spacing double
Given Weights: Mean-CVaR with Rebalancing and Compounding
\end_layout

\begin_layout Section
\paragraph_spacing double
Results
\end_layout

\begin_layout Standard
\paragraph_spacing double
[Results, data, graphs]
\end_layout

\begin_layout Subsection
\paragraph_spacing double
Analytical Mean Variance
\end_layout

\begin_layout Standard
\paragraph_spacing double
\begin_inset Graphics
	filename C:/Documents and Settings/Irvin/My Documents/workspace/EconThesis/Refactored_Code/graphs and data/2010-03-02 rebalancing compounding/10 yrs/200 sims 10 yrs - mean variance.jpg
	width 5in
	height 3in

\end_inset


\end_layout

\begin_layout Subsection
\paragraph_spacing double
Single Period (buy and hold) Mean-CVaR
\end_layout

\begin_layout Standard
\paragraph_spacing double
We first used the resulting weights of the analytical, normal-mean variance
 efficient frontiers to find their corresponding portfolio CVaR's given
 the simulation data.
 We used this as a comparison to the actual 'optimal' set of portfolios
 in a mean-CVaR framework, which we find using MATLAB's 
\family sans
fmincon()
\family default
 function.
 The results indicate that there exists a set of portfolios that has a lower
 CVaR (or higher return) than any of the analytical mean variance portfolios.
 
\end_layout

\begin_layout Standard
\paragraph_spacing double
\begin_inset Graphics
	filename C:/Documents and Settings/Irvin/My Documents/workspace/EconThesis/Refactored_Code/graphs and data/2010-03-02 rebalancing compounding/10 yrs/200 sims - 10 yrs - one period cvar.jpg
	width 5in
	height 3in

\end_inset


\end_layout

\begin_layout Subsection
\paragraph_spacing double
Rebalancing and Compounding Mean-CVaR
\end_layout

\begin_layout Standard
\paragraph_spacing double
\begin_inset Graphics
	filename C:/Documents and Settings/Irvin/My Documents/workspace/EconThesis/Refactored_Code/graphs and data/2010-03-02 rebalancing compounding/10 yrs/w uns given/200 sims 10 years - w uns given.jpg
	width 5in
	height 3in

\end_inset


\end_layout

\begin_layout Section
\paragraph_spacing double
Discussion
\end_layout

\begin_layout Standard
\paragraph_spacing double
[Interpretation of results, implications]
\end_layout

\begin_layout Section
\paragraph_spacing double
Conclusion
\end_layout

\begin_layout Standard
\paragraph_spacing double
[Concluding thoughts]
\end_layout

\end_body
\end_document
@


1.6
log
@*** empty log message ***
@
text
@@


1.5
log
@*** empty log message ***
@
text
@a7 1
\@@addtoreset{equation}{subsection} 
@


1.4
log
@*** empty log message ***
@
text
@d50 1
d55 1
d60 1
d65 1
d71 1
d76 1
d81 1
d86 1
d94 1
d99 1
d107 1
d112 1
d120 1
d125 1
d133 1
d138 1
d143 1
d148 1
d153 1
d193 1
d198 1
d244 1
d261 1
d283 1
d299 1
d304 1
d309 1
d314 1
d319 1
d325 1
d330 1
d348 1
d370 1
d386 1
d394 1
d399 1
d419 1
d424 1
d447 1
d459 1
d469 1
d523 1
d528 1
d566 1
d585 1
d590 1
d624 1
d634 1
d678 1
d683 1
d695 1
d705 1
d715 1
d725 1
d735 1
d745 1
d773 1
d778 1
d797 1
d806 1
d822 1
d827 1
d832 1
d842 1
d869 1
d879 1
d889 1
d918 1
d946 1
d956 1
d973 1
d982 1
d1030 1
d1035 1
d1040 1
d1064 1
d1092 1
d1102 1
d1119 1
d1124 1
d1129 1
d1134 1
d1139 1
d1144 1
d1149 1
d1154 1
d1159 1
d1162 2
d1171 1
d1176 1
d1192 1
d1195 2
d1204 1
d1209 1
d1212 2
a1213 1
	scale 90
d1221 1
d1226 1
d1231 1
d1236 1
@


1.3
log
@*** empty log message ***
@
text
@d201 11
a211 4
  Mathematically this can be represented as Rebalancing Benefit = where
 delta is the deviation from the target allocation and Tracking Error represents
 how closely a portfolio follows the target allocation to which it is benchmarke
d.
@


1.2
log
@draft combined update
@
text
@d130 2
a131 2
\begin_layout Standard
[Lit review text]
d289 1
a289 1
Methods Overview
d360 1
a360 1
  The shortfall of this method is the thinness of the tail, implying a very
d363 1
a363 1
  The advantage of using a t-copula is it can account for higher probabilities
d365 1
a365 1
  A copula combines marginal cumulative distribution functions (CDF) and
d368 1
a368 1
  A Gaussian copula assumes a multivariate normal distribution whereas a
d371 1
a371 1
  The t-copula provides a more accurate representation of real world financial
d380 2
a381 2
The historical data of each individual asset classes are first fit to independen
t, marginal Generalized Pareto Distribution; this GPD fit is piecewise so
d384 1
a384 1
  Next, independent marginal CDFs are transformed into their inverses, creating
d386 1
a386 1
  The historical returns are then applied to their respective inverse CDF's
d388 1
a388 1
  Using MATLAB's 
d395 1
a395 1
  The resulting t-Copula fit is centered at zero with characteristic fat
d398 1
a398 1
  
d404 2
a405 2
  A single month's return is simulated for all asset classes by generating
 multivariate t random numbers from the t-Copula fit using MATLAB's 
d464 1
a464 1
  We use the average historical, empirical monthly returns and historical,
d468 2
a469 2
  When simulations are drawn out of a t-copula, the likelihood of a market
 crash scenario is an order of magnitude higher than that in a Gaussian
d471 1
a471 1
  
d481 1
a481 1
  Variance accounts for both upside risk and downside risk since it is simply
d484 5
a488 4
  When investment managers look at risk, they are typically concerned with
 downside risk or losses and view upside risk as a result of skill, expertise,
 good fortune, and value added.
  Value-at-risk (VaR) has been incorporated as another risk measure that
d490 1
a490 1
  VaR is the minimum loss expected at a certain confidence level (typically
d494 1
a494 1
  Although VaR does a better job of accounting for downside risk than variance,
d497 1
a497 1
  It is possible to have two PDF’s with the same VaR (loss associated with
d500 13
a512 10
  Conditional value-at-risk (CVaR) attempts to rectify this problem: it
 is the expected loss given a loss beyond the value-at-risk, and can be
 calculated as a weighted average of the worst case losses.
  Furthermore, CVaR is a better risk measure than VaR because it is a “coherent
 risk measure” and is “sub-additive and convex”, where the CVaR of a portfolio
 is always less than or equal to the sum of the CVaR of the weights of the
 individual asset classes and can be extended from continuous probability
 distributions to discrete screnarios such as in simulations (Krohmal, Palmquist
, and Uryasev, 2002).
  
d518 2
a519 2
  The ability to use linear programming stems from how CVaR is calculated.
  Theoretically, CVaR is simply the average value beyond the specified cutoff
d521 4
a524 4
  Rockafellar and Uryasev demonstrated that the use of simulations and a
 summation to estimate the theoretical CVaR can be effectively used to find
 the minimum CVaR.
  The minimization of CVaR in most situations also provides a minimum VaR
d526 1
a526 1
  Only in situations of extreme skewness does the minimum VaR differ greatly
d528 3
a530 3
  Rockafellar and Uryasev demonstrate the theoretical and mathematical possibili
ty of optimizing CVaR for portfolio asset allocation.
  
d566 2
a567 2
 is the desired CVaR level such as 5%.
  
d619 1
a619 1
  
d626 105
d1059 55
@


1.1
log
@'irvin's edits, and updated combined'
@
text
@d6 4
d24 1
d138 1
a138 1
 They conclude that a fat tail distribution better describes the real world
d140 1
a140 1
 The paper also briefly touches on CVaR as a risk measure that better accounts
d142 1
a142 1
 JPMorgan first tests for 1st degree auto-correlation between consecutive
d145 4
a148 4
 Then, the technique used is to fit the historical data to a normal distribution
 and a fat tail (Generalized Pareto) distribution, followed by the use of
 copulas to account for the joint distribution of asset classes.
 In other words, the copulas account for the probability of the behavior
d150 1
a150 1
 The historical data is then fit to a normal copula (Gaussian copula) and
d154 2
a155 2
 The paper then draws simulations out of these two copulas to simulate a
 set of returns for a time period and compares it to the historical data.
d159 1
a159 1
 It shows that the use of a Student’s t-copula assumption provides a lower
d161 1
a161 1
 JPMorgan’s paper demonstrates an implementation of the t-copula and CVaR
d164 1
a164 1
 Our research will focus on the implementation and continuation of this
d167 1
a167 1
 We will also look at the historical accuracy and advantage of using our
d170 95
a264 1
 
d296 1
a296 1
 The historical return data of our asset classes benchmarks are first tested
d299 1
a299 1
 Next, the historical return data are individually fit to marginal Generalized
d302 1
a302 1
 We then run simulations for monthly returns for 3 years by drawing out
d304 3
a306 3
 We optimize our efficient frontier for return and CVaR based on this simulation
 dataset only.
 
d312 1
a312 1
 The weights of the mean-variance efficient frontiers for historical arithmetic
d315 1
a315 1
 The pseudo-mean-CVaR efficient frontier derived from these mean-variance
d319 1
a319 1
 We use MATLAB's built-in optimization function 'fmincon' for finding an
d321 1
a321 1
 The objective function to be minimized is the CVaR while the non-linear
d324 2
a325 2
 We generate an efficient frontier by using each of the historical mean-variance
 portfolio returns as our non-linear constraints for finding the minimum
d327 1
a327 1
 
d333 1
a333 1
 We first implement a simple model that rebalances back to the target weight
d335 1
a335 1
 We integrate the rebalancing function to our objective function in calculating
d338 1
a338 1
 We are currently investigating the use of a decision function for determining
d342 1
a342 1
 
d348 1
a348 1
 We will use historical data as well as newly generated simulation data
d360 1
a360 1
 The shortfall of this method is the thinness of the tail, implying a very
d363 1
a363 1
 The advantage of using a t-copula is it can account for higher probabilities
d365 1
a365 1
 A copula combines marginal cumulative distribution functions (CDF) and
d368 1
a368 1
 A Gaussian copula assumes a multivariate normal distribution whereas a
d371 1
a371 1
 The t-copula provides a more accurate representation of real world financial
d384 1
a384 1
 Next, independent marginal CDFs are transformed into their inverses, creating
d386 1
a386 1
 The historical returns are then applied to their respective inverse CDF's
d388 1
a388 1
 Using MATLAB's 
d395 1
a395 1
 The resulting t-Copula fit is centered at zero with characteristic fat
d398 1
a398 1
 
d404 1
a404 1
 A single month's return is simulated for all asset classes by generating
d464 1
a464 1
 We use the average historical, empirical monthly returns and historical,
d468 1
a468 1
 When simulations are drawn out of a t-copula, the likelihood of a market
d471 1
a471 1
 
d481 1
a481 1
 Variance accounts for both upside risk and downside risk since it is simply
d484 1
a484 1
 When investment managers look at risk, they are typically concerned with
d487 1
a487 1
 Value-at-risk (VaR) has been incorporated as another risk measure that
d489 1
a489 1
 VaR is the minimum loss expected at a certain confidence level (typically
d493 1
a493 1
 Although VaR does a better job of accounting for downside risk than variance,
d496 1
a496 1
 It is possible to have two PDF’s with the same VaR (loss associated with
d499 4
a502 4
 Conditional value-at-risk (CVaR) attempts to rectify this problem: it is
 the expected loss given a loss beyond the value-at-risk, and can be calculated
 as a weighted average of the worst case losses.
 Furthermore, CVaR is a better risk measure than VaR because it is a “coherent
d508 1
a508 1
 
d514 2
a515 2
 The ability to use linear programming stems from how CVaR is calculated.
 Theoretically, CVaR is simply the average value beyond the specified cutoff
d517 1
a517 1
 Rockafellar and Uryasev demonstrated that the use of simulations and a
d520 1
a520 1
 The minimization of CVaR in most situations also provides a minimum VaR
d522 1
a522 1
 Only in situations of extreme skewness does the minimum VaR differ greatly
d524 3
a526 3
 Rockafellar and Uryasev demonstrate the theoretical and mathematical possibilit
y of optimizing CVaR for portfolio asset allocation.
 
d563 1
a563 1
 
d615 1
a615 1
 
d631 10
a640 2
[objective function = minimize CVaR]
\end_layout
d642 1
a642 2
\begin_layout Standard
[constraints]
d649 2
a650 2
\begin_layout Subsection
Simulated Mean-CVaR Optimization with Rebalancing and Compounding
d654 5
a658 23
The literature reviewed up to this point only considers a single time frame
 portfolio optimization, where an asset allocation is set at the beginning
 of the period and the portfolio is untouched until the end of the investment
 period.
 Seth J.
 Master's a simple rebalancing strategy involves setting a target allocation
 and an investor only rebalances when the allocation deviates beyond a set
 of trigger points.
 For instance, if the trigger point is 3% for all asset classes, then an
 investor only rebalances when the weight for any asset class deviation
 more than 3% from the target weight.
 This is also known as a tolerance band rebalancing strategy.
 According to Seth Master, any rebalancing strategy should incorporate some
 basic assumptions.
 The benefit of rebalancing is inversely proportional to an investor's risk
 preference: if an investor is risk tolerant, meaning he is willing to endure
 higher risk for higher potential returns, then his benchmarks will be smaller,
 meaning he will rebalance less often.
 Assuming transaction costs are fixed and not proportional to the transaction
 size, the cost of rebalancing is linear: selling twice as much of an asset
 would cost twice as much.
 The net benefit of rebalancing is the difference between the benefit of
 rebalancing and the cost of rebalancing.
d663 23
a685 13
Walter Sun extended the idea of Seth Master’s paper to incorporate dynamic
 programming to minimize cost of rebalancing.
 Walter applies the idea to CAPM models, which assume that asset returns
 are stationary, and that mean and variance are the primary portfolio statistics
 of interest.
 The optimal strategy is that one rebalances only when the expected cost
 of trading is less than the expected cost of doing nothing.
 His conclusion is that periodic or tolerance band rebalancing provide suboptima
l rebalance portfolios.
 However, by treating rebalancing problem as an optimization problem and
 solving it using dynamic programming, he was able to reduce overall costs
 of portfolio rebalancing.
 
d689 6
a694 18
Taking rebalancing one step further, Gianfranco Guastaroba applied rebalancing
 strategies to portfolio optimization model that uses Conditional Value
 at Risk (CVaR) as a measure of risk, the same framework we are using.
 The model incorporated rebalancing as a set of linear programming constraints.
 He introduced a decision variable that indicated whether to rebalance based
 on whether portfolio allocation deviated from a certain quantile.
 He also specified a fixed cost and a variable cost for buying/selling assets.
 The constraint was that, during every rebalancing period, an investor rebalance
d if net portfolio return taking into account fixed and proportional transaction
 costs is at least the predetermined required return.
 The paper then used four in-sample-out-of-sample windows to test the model
 for different levels of minimum required returns (0, 5%, and 10%) and different
 quantile measures (1%, 5%, 10% and 25%).
 He concluded that for a very risk-averse investor the best choice is to
 rebalance two or three times in six months.
 On the other hand, a less risk-averse investor should rebalance one time
 or not rebalance at all.
 
d698 5
a702 12
These papers give us a starting point for incorporating rebalancing into
 our model.
 Our goal is to analyze and compare the different rebalancing strategies
 available: a simple periodic strategy in which we rebalance every few months,
 a tolerance-band strategy in which we rebalance when allocation deviates
 beyond a predetermined range, or a dynamic programming approach that actively
 calculates the expected cost of future transactions.
 We will then incorporate the use of t-copulas for fat tails, CVaR as a
 risk measure, and rebalancing as a portfolio strategy to produce a realistic
 asset allocation framework for a large institutional investor such as an
 endowment.
\end_layout
a703 2
\begin_layout Subsubsection
Implementation
d707 22
a728 9
In our implementation, we adopt a 12-month periodic rebalancing strategy.
 We have 5000 simulations of returns for seven asset classes, a set of starting
 weights derived from the mean and variance framework, and a set of fixed
 portfolio returns.
 Every 12 months, we sum up the returns in that year and we distribute the
 portfolio value according to a predetermined set of weights, and then compound
 it with future returns.
 
\end_layout
d730 2
a731 3
\begin_layout Standard
Our rebalancing framework could thus be expressed as a linear programming
 minimization problem: 
d758 7
a764 2
where 
\begin_inset Formula $R$
a766 3
 is the fixed portfolio monthly return rate and 
\begin_inset Formula $\tilde{R}$
\end_inset
a767 2
 is the calculated portfolio monthly return at each run of the simulation.
 
d771 2
a772 4
Our goal is to find the set of weights that will minimize CVaR given a fixed
 level of return.
 Our two linear constraints indicate that the weights must be nonnegative
 since no borrowing is allowed and that the weights sum up to one.
d779 1
a779 1
 is the same as the given fixed portfolio return 
d788 30
a817 5
 CVaR is calculated analatically by trying out a set of asset weights all
 5000 simulations.
 Each simulation gives a final portfolio value, from which we could derive
 the monthly retun rate.
 For instance, suppose we start with 1 (billion) endowment, and the final
d821 1
a821 1
\begin_inset Formula $\frac{24.62^{1/35}-1}{12}$
d824 10
a833 9
 = 0.00799 monthly return rate.
 For each set of trying weights, we go throught all 5000 simulations, giving
 us 5000 monthly return rates.
 To calculate the CVaR, we take the average of the lowest 5%, or 250 final
 returns.
 That is our CVaR.
 We will keep trying weigts in an analytical fashion until we find the minimun
 CVaR.
 The MATLAB funtion 
d837 23
a859 3
 allows us to do this.
 The objective function and the constraints are precisely the same as in
 the linear programming problem.
d861 61
@

